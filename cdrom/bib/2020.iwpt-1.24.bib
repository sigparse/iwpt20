@InProceedings{hershcovich-EtAl:2020:IWPT,
  author    = {Hershcovich, Daniel  and  de Lhoneux, Miryam  and  Kulmizev, Artur  and  Pejhan, Elham  and  Nivre, Joakim},
  title     = {KøPsala: Transition-Based Graph Parsing via Efficient Training and Effective Encoding},
  booktitle      = {Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies},
  month          = {July},
  year           = {2020},
  address        = {Online},
  publisher      = {Association for Computational Linguistics},
  pages     = {235--243},
  abstract  = {We present Køpsala, the Copenhagen-Uppsala system for the Enhanced Universal Dependencies Shared Task at IWPT 2020. Our system is a pipeline consisting of off-the-shelf models for everything but enhanced graph parsing, and for the latter, a transition-based graph parser adapted from Che et al. (2019). We train a single enhanced parser model per language, using gold sentence splitting and tokenization for training, and rely only on tokenized surface forms and multilingual BERT for encoding. While a bug introduced just before submission resulted in a severe drop in precision, its post-submission fix would bring us to 4th place in the official ranking, according to average ELAS. Our parser demonstrates that a unified pipeline is effective for both Meaning Representation Parsing and Enhanced Universal Dependencies.},
  url       = {https://www.aclweb.org/anthology/2020.iwpt-1.24}
}

